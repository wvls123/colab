{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wvls123/colab/blob/main/%D0%92%D0%B5%D0%B1%D0%B8%D0%BD%D0%B0%D1%80_18_%D0%BD%D0%BE%D1%8F%D0%B1%D1%80%D1%8F_Weweb_%2B_GPT_%D0%94%D0%B5%D0%BD%D1%8C_1_%D0%9A%D0%BE%D0%BB%D0%B0%D0%B1_%D0%B0%D1%81%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BD%D1%82%D0%B0_%D0%BF%D0%BE_%D0%B1%D1%80%D0%B5%D0%BD%D0%B4%D1%83.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–†–∞–±–æ—á–∏–π –æ—Ç VC  gpt (—Å –ø–∏–Ω–≥–∞–º–∏)"
      ],
      "metadata": {
        "id": "Nz2aYhQ4B0du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "#  NeuroAnalyst Backend FINAL STABLE VERSION\n",
        "# ==========================================================\n",
        "#  ‚úî –ü–∞—Ä—Å–∏–Ω–≥ —Å–∞–π—Ç–∞ (—É—Å—Ç–æ–π—á–∏–≤—ã–π)\n",
        "#  ‚úî –û—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–∏ (—á–µ—Ä–µ–∑ Google Doc)\n",
        "#  ‚úî Follow-up –∞–Ω–∞–ª–∏–∑ (—á–µ—Ä–µ–∑ –¥—Ä—É–≥–æ–π Google Doc)\n",
        "#  ‚úî Follow-up –ù–ï –ø–æ–ª—É—á–∞–µ—Ç site_data\n",
        "#  ‚úî –ï–¥–∏–Ω—ã–π JSON –≤—Ö–æ–¥ –¥–ª—è follow-up\n",
        "#  ‚úî –ò—Å—Ç–æ—Ä–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ role/content\n",
        "#  ‚úî Cloudflared —Ç—É–Ω–Ω–µ–ª—å\n",
        "#  ‚úî CORS –¥–ª—è WeWeb\n",
        "#  ‚úî –ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –æ—à–∏–±–∫–∏ link undefined, mailto, tel, javascript\n",
        "#  ‚úî –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü depth=1, max_pages=15\n",
        "# ==========================================================\n",
        "\n",
        "\n",
        "!pip install openai flask flask-cors beautifulsoup4 requests tldextract >/dev/null\n",
        "import os, re, json, time, threading, subprocess, urllib.request, uuid, logging\n",
        "from datetime import datetime, timedelta\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse, urljoin\n",
        "from getpass import getpass\n",
        "import tldextract\n",
        "import requests\n",
        "from openai import OpenAI\n",
        "# -------------------------------\n",
        "# ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n",
        "# -------------------------------\n",
        "PORT = 8000\n",
        "CLOUDFLARED_PATH = \"/usr/local/bin/cloudflared\"\n",
        "MAIN_PROMPT_URL = \"https://docs.google.com/document/d/1DtA6CzcNeoZSDwj043YmE84XMnv1LAp_Z3MWxP8n55M/edit\"\n",
        "FOLLOWUP_PROMPT_URL = \"https://docs.google.com/document/d/12nwxCLf4Gk4daR7ecRA04rZe-RToNb8-TAtERzY4o0E/edit\"\n",
        "SESSION_TTL_HOURS = 24\n",
        "MAX_SESSIONS = 100\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
        "    datefmt='%H:%M:%S'\n",
        ")\n",
        "logger = logging.getLogger(\"neuro-analyst\")\n",
        "if not os.path.exists(CLOUDFLARED_PATH):\n",
        "    print(\"üîΩ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é cloudflared...\")\n",
        "    url = \"https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\"\n",
        "    urllib.request.urlretrieve(url, \"cloudflared\")\n",
        "    os.rename(\"cloudflared\", CLOUDFLARED_PATH)\n",
        "    os.chmod(CLOUDFLARED_PATH, 0o755)\n",
        "else:\n",
        "    print(\"‚úÖ Cloudflared —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.\")\n",
        "# -------------------------------\n",
        "# üìÑ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∏–∑ Google Docs\n",
        "# -------------------------------\n",
        "def fetch_gdoc_text(gdoc_url: str) -> str:\n",
        "    try:\n",
        "        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º URL –≤ —Ñ–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞ —Ç–µ–∫—Å—Ç–∞\n",
        "        if '/edit' in gdoc_url:\n",
        "            export_url = gdoc_url.replace('/edit', '/export?format=txt')\n",
        "        elif '/view' in gdoc_url:\n",
        "            export_url = gdoc_url.replace('/view', '/export?format=txt')\n",
        "        else:\n",
        "            # –ï—Å–ª–∏ URL —É–∂–µ –≤ –¥—Ä—É–≥–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –¥–æ–±–∞–≤–ª—è–µ–º —ç–∫—Å–ø–æ—Ä—Ç\n",
        "            export_url = gdoc_url.rstrip('/') + '/export?format=txt'\n",
        "\n",
        "        logger.info(f\"üì• –ó–∞–≥—Ä—É–∂–∞—é –¥–æ–∫—É–º–µ–Ω—Ç: {export_url}\")\n",
        "\n",
        "        r = requests.get(export_url)\n",
        "        if r.status_code != 200:\n",
        "            raise ValueError(f\"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Google Doc: {r.status_code}\")\n",
        "\n",
        "        text = r.text.strip()\n",
        "\n",
        "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ —Ç–µ–∫—Å—Ç, –∞ –Ω–µ HTML\n",
        "        if text.startswith('<!DOCTYPE') or text.startswith('<html'):\n",
        "            raise ValueError(\"–ü–æ–ª—É—á–µ–Ω HTML –≤–º–µ—Å—Ç–æ —Ç–µ–∫—Å—Ç–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –¥–æ–∫—É–º–µ–Ω—Ç –ø—É–±–ª–∏—á–Ω–æ –¥–æ—Å—Ç—É–ø–µ–Ω\")\n",
        "\n",
        "        logger.info(f\"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω Google Doc\")\n",
        "        logger.info(f\"üìä –†–∞–∑–º–µ—Ä: {len(text):,} —Å–∏–º–≤–æ–ª–æ–≤ (~{len(text)//4:,} —Ç–æ–∫–µ–Ω–æ–≤)\")\n",
        "\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}\")\n",
        "# -------------------------------\n",
        "# üåê –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Å—ã–ª–æ–∫\n",
        "# -------------------------------\n",
        "def normalize_link(base, href: str):\n",
        "    if not href or not isinstance(href, str):\n",
        "        return None\n",
        "    href = href.strip()\n",
        "    bad_prefixes = (\n",
        "        \"mailto:\", \"tel:\", \"javascript:\", \"whatsapp:\", \"viber:\",\n",
        "        \"tg:\", \"#\", \"sms:\", \"skype:\",\n",
        "    )\n",
        "    if href.startswith(bad_prefixes):\n",
        "        return None\n",
        "    if href.startswith(\"http://\") or href.startswith(\"https://\"):\n",
        "        return href.split(\"#\")[0]\n",
        "    if href.startswith(\"//\"):\n",
        "        return \"https:\" + href.split(\"#\")[0]\n",
        "    return urljoin(base, href.split(\"#\")[0])\n",
        "# -------------------------------\n",
        "# üîé –ü–∞—Ä—Å–∏–Ω–≥ —Å–∞–π—Ç–∞\n",
        "# -------------------------------\n",
        "def same_domain(a, b):\n",
        "    try:\n",
        "        return tldextract.extract(a).registered_domain == tldextract.extract(b).registered_domain\n",
        "    except:\n",
        "        return False\n",
        "def safe_json(obj):\n",
        "    try:\n",
        "        json.dumps(obj)\n",
        "        return obj\n",
        "    except:\n",
        "        return str(obj)\n",
        "def crawl_site(start_url, max_pages=15, depth=1):\n",
        "    logger.info(f\"üîé –ù–∞—á–∏–Ω–∞—é –ø–∞—Ä—Å–∏–Ω–≥: {start_url}\")\n",
        "    logger.info(f\"‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏: max_pages={max_pages}, depth={depth}\")\n",
        "\n",
        "    visited, queue = set(), [(start_url, 0)]\n",
        "    pages = []\n",
        "    total_text_chars = 0\n",
        "    while queue and len(pages) < max_pages:\n",
        "        url, d = queue.pop(0)\n",
        "        if url in visited or d > depth:\n",
        "            continue\n",
        "        visited.add(url)\n",
        "        logger.info(f\"üåê –ü–∞—Ä—Å–∏–º [{len(pages)+1}/{max_pages}]: {url}\")\n",
        "        try:\n",
        "            r = requests.get(url, timeout=8, headers={\"User-Agent\": \"NeuroAnalystBot/1.0\"})\n",
        "            if r.status_code != 200:\n",
        "                logger.warning(f\"‚ö†Ô∏è –°—Ç–∞—Ç—É—Å {r.status_code}, –ø—Ä–æ–ø—É—Å–∫–∞—é\")\n",
        "                continue\n",
        "            soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "            for s in soup([\"script\", \"style\", \"noscript\"]):\n",
        "                s.extract()\n",
        "            title = soup.title.string.strip() if soup.title else \"\"\n",
        "            text = soup.get_text(\"\\n\", strip=True)\n",
        "\n",
        "            original_len = len(text)\n",
        "            text = text[:20000]\n",
        "            total_text_chars += len(text)\n",
        "            meta = {\n",
        "                m.get(\"name\", m.get(\"property\", \"\")): m.get(\"content\", \"\")\n",
        "                for m in soup.find_all(\"meta\")\n",
        "                if m.get(\"name\") or m.get(\"property\")\n",
        "            }\n",
        "            links = []\n",
        "            for a in soup.find_all(\"a\", href=True):\n",
        "                link = normalize_link(url, a[\"href\"])\n",
        "                if not link:\n",
        "                    continue\n",
        "                if same_domain(start_url, link):\n",
        "                    links.append(link)\n",
        "            page_data = {\n",
        "                \"url\": url,\n",
        "                \"title\": title,\n",
        "                \"meta\": safe_json(meta),\n",
        "                \"text\": text,\n",
        "                \"links\": links\n",
        "            }\n",
        "\n",
        "            page_json = json.dumps(page_data, ensure_ascii=False)\n",
        "            page_json_len = len(page_json)\n",
        "\n",
        "            logger.info(f\" ‚îú‚îÄ –ó–∞–≥–æ–ª–æ–≤–æ–∫: {title[:50]}...\")\n",
        "            logger.info(f\" ‚îú‚îÄ –¢–µ–∫—Å—Ç: {original_len:,} ‚Üí {len(text):,} —Å–∏–º–≤–æ–ª–æ–≤\")\n",
        "            logger.info(f\" ‚îú‚îÄ JSON: {page_json_len:,} —Å–∏–º–≤–æ–ª–æ–≤ (~{page_json_len//4:,} —Ç–æ–∫–µ–Ω–æ–≤)\")\n",
        "            logger.info(f\" ‚îî‚îÄ –°—Å—ã–ª–æ–∫: {len(links)}\")\n",
        "\n",
        "            pages.append(page_data)\n",
        "            for l in links:\n",
        "                if l not in visited:\n",
        "                    queue.append((l, d + 1))\n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {url}: {e}\")\n",
        "    result = {\"start_url\": start_url, \"pages\": pages, \"count\": len(pages)}\n",
        "    result_json = json.dumps(result, ensure_ascii=False)\n",
        "    result_json_len = len(result_json)\n",
        "\n",
        "    logger.info(\"=\" * 60)\n",
        "    logger.info(f\"‚úÖ –ü–ê–†–°–ò–ù–ì –ó–ê–í–ï–†–®–Å–ù\")\n",
        "    logger.info(f\"üìä –°—Ç—Ä–∞–Ω–∏—Ü: {len(pages)}\")\n",
        "    logger.info(f\"üìä –¢–µ–∫—Å—Ç–∞: {total_text_chars:,} —Å–∏–º–≤–æ–ª–æ–≤\")\n",
        "    logger.info(f\"üìä JSON: {result_json_len:,} —Å–∏–º–≤–æ–ª–æ–≤ (~{result_json_len//4:,} —Ç–æ–∫–µ–Ω–æ–≤)\")\n",
        "    logger.info(\"=\" * 60)\n",
        "\n",
        "    return result\n",
        "# -------------------------------\n",
        "# ü§ñ –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å —Å –∂—ë—Å—Ç–∫–æ–π JSON —Å—Ö–µ–º–æ–π\n",
        "# -------------------------------\n",
        "def call_main_model(client, prompt_text, site_data):\n",
        "    logger.info(\"ü§ñ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ GPT...\")\n",
        "\n",
        "    user_content = json.dumps({\"site\": site_data}, ensure_ascii=False)\n",
        "\n",
        "    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–≥–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∫ –ø—Ä–æ–º–ø—Ç—É\n",
        "    enhanced_prompt = prompt_text + \"\"\"\n",
        "\n",
        "–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û - –°–¢–†–û–ì–ò–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø:\n",
        "\n",
        "–ò–°–ü–û–õ–¨–ó–£–ô –¢–û–õ–¨–ö–û –≠–¢–ò –ü–û–õ–Ø:\n",
        "{\n",
        "  \"reasoning\": {\"goals\": \"...\", \"dialog_stage\": \"...\", \"plan\": [...]},\n",
        "  \"analysis\": {\"archetypes\": {...}, \"summary\": \"...\"},\n",
        "  \"insights\": {\n",
        "    \"strengths\": [...],\n",
        "    \"weaknesses\": [...],\n",
        "    \"recommendations\": {\"strengthen\": [...], \"balance\": [...], \"add\": [...]},\n",
        "    \"overall_comment\": \"...\"\n",
        "  },\n",
        "  \"strategies\": [...],\n",
        "  \"chat_summary\": \"...\",\n",
        "  \"next_question\": \"...\"\n",
        "}\n",
        "\n",
        "–ó–ê–ü–†–ï–©–ï–ù–û –¥–æ–±–∞–≤–ª—è—Ç—å: notes_on_source, recommendations_for_action, data_quality, assumptions.\n",
        "\n",
        "–í–ê–ñ–ù–û: –ù–µ —É–ø–æ–º–∏–Ω–∞–π –≤ —Ç–µ–∫—Å—Ç–µ \"–ø–æ —à–∞–≥—É X –∏–∑ –ø–ª–∞–Ω–∞\", \"—Å–æ–≥–ª–∞—Å–Ω–æ –ø–ª–∞–Ω—É\", \"–Ω–∞ —à–∞–≥–µ N\".\n",
        "Reasoning - —ç—Ç–æ —Ç–≤–æ–π –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –ø–ª–∞–Ω, –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –µ–≥–æ –Ω–µ –≤–∏–¥–∏—Ç.\n",
        "–ü–∏—à–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –±–µ–∑ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É.\n",
        "\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": enhanced_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_content},\n",
        "    ]\n",
        "\n",
        "    system_len = len(enhanced_prompt)\n",
        "    user_len = len(user_content)\n",
        "    total_len = system_len + user_len\n",
        "\n",
        "    logger.info(f\"üìä System: {system_len:,} —Å–∏–º–≤. (~{system_len//4:,} —Ç–æ–∫–µ–Ω–æ–≤)\")\n",
        "    logger.info(f\"üìä User: {user_len:,} —Å–∏–º–≤. (~{user_len//4:,} —Ç–æ–∫–µ–Ω–æ–≤)\")\n",
        "    logger.info(f\"üìä –ò–¢–û–ì–û: {total_len:,} —Å–∏–º–≤. (~{total_len//4:,} —Ç–æ–∫–µ–Ω–æ–≤)\")\n",
        "    logger.info(f\"üöÄ –ó–∞–ø—Ä–æ—Å –∫ gpt-5-mini...\")\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-5-mini\",\n",
        "        messages=messages,\n",
        "        response_format={\"type\": \"json_object\"}\n",
        "    )\n",
        "\n",
        "    output_text = resp.choices[0].message.content\n",
        "    output_len = len(output_text)\n",
        "\n",
        "    logger.info(f\"‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω\")\n",
        "    logger.info(f\"üìä Output: {output_len:,} —Å–∏–º–≤. (~{output_len//4:,} —Ç–æ–∫–µ–Ω–æ–≤)\")\n",
        "    logger.info(f\"üìä API —Ç–æ–∫–µ–Ω—ã: input={resp.usage.prompt_tokens:,}, output={resp.usage.completion_tokens:,}, total={resp.usage.total_tokens:,}\")\n",
        "\n",
        "    return resp\n",
        "# -------------------------------\n",
        "# ü§ñ Follow-up –º–æ–¥–µ–ª—å\n",
        "# -------------------------------\n",
        "def call_followup_model(client, followup_prompt_text, json_payload):\n",
        "    logger.info(\"üí¨ Follow-up –∑–∞–ø—Ä–æ—Å...\")\n",
        "\n",
        "    user_content = json.dumps(json_payload, ensure_ascii=False)\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": followup_prompt_text},\n",
        "        {\"role\": \"user\", \"content\": user_content},\n",
        "    ]\n",
        "\n",
        "    system_len = len(followup_prompt_text)\n",
        "    user_len = len(user_content)\n",
        "    total_len = system_len + user_len\n",
        "\n",
        "    logger.info(f\"üìä System: {system_len:,} —Å–∏–º–≤. (~{system_len//4:,} —Ç–æ–∫–µ–Ω–æ–≤)\")\n",
        "    logger.info(f\"üìä User: {user_len:,} —Å–∏–º–≤. (~{user_len//4:,} —Ç–æ–∫–µ–Ω–æ–≤)\")\n",
        "    logger.info(f\"üìä –ò–¢–û–ì–û: {total_len:,} —Å–∏–º–≤. (~{total_len//4:,} —Ç–æ–∫–µ–Ω–æ–≤)\")\n",
        "    logger.info(f\"üöÄ –ó–∞–ø—Ä–æ—Å –∫ gpt...\")\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4.1\",\n",
        "        messages=messages,\n",
        "        response_format={\"type\": \"json_object\"}\n",
        "    )\n",
        "\n",
        "    output_text = resp.choices[0].message.content\n",
        "    output_len = len(output_text)\n",
        "\n",
        "    logger.info(f\"‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω\")\n",
        "    logger.info(f\"üìä Output: {output_len:,} —Å–∏–º–≤. (~{output_len//4:,} —Ç–æ–∫–µ–Ω–æ–≤)\")\n",
        "    logger.info(f\"üìä API —Ç–æ–∫–µ–Ω—ã: input={resp.usage.prompt_tokens:,}, output={resp.usage.completion_tokens:,}, total={resp.usage.total_tokens:,}\")\n",
        "\n",
        "    return resp\n",
        "# -------------------------------\n",
        "# üóÑÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏—è–º–∏\n",
        "# -------------------------------\n",
        "STORE = {}\n",
        "def cleanup_old_sessions():\n",
        "    now = datetime.now()\n",
        "    to_delete = []\n",
        "\n",
        "    for sid, sess in STORE.items():\n",
        "        created_at = sess.get(\"created_at\")\n",
        "        if created_at and (now - created_at) > timedelta(hours=SESSION_TTL_HOURS):\n",
        "            to_delete.append(sid)\n",
        "\n",
        "    for sid in to_delete:\n",
        "        del STORE[sid]\n",
        "        logger.info(f\"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è —Å–µ—Å—Å–∏—è: {sid}\")\n",
        "\n",
        "    if to_delete:\n",
        "        logger.info(f\"üßπ –û—á–∏—â–µ–Ω–æ {len(to_delete)} —Å—Ç–∞—Ä—ã—Ö —Å–µ—Å—Å–∏–π\")\n",
        "def limit_sessions():\n",
        "    if len(STORE) > MAX_SESSIONS:\n",
        "        sorted_sessions = sorted(\n",
        "            STORE.items(),\n",
        "            key=lambda x: x[1].get(\"created_at\", datetime.min)\n",
        "        )\n",
        "\n",
        "        to_delete = len(STORE) - MAX_SESSIONS\n",
        "        for sid, _ in sorted_sessions[:to_delete]:\n",
        "            del STORE[sid]\n",
        "            logger.info(f\"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ —Å–µ—Å—Å–∏—è (–ª–∏–º–∏—Ç): {sid}\")\n",
        "\n",
        "        logger.info(f\"üßπ –û—á–∏—â–µ–Ω–æ {to_delete} —Å–µ—Å—Å–∏–π (–ª–∏–º–∏—Ç –¥–æ—Å—Ç–∏–≥–Ω—É—Ç)\")\n",
        "# -------------------------------\n",
        "# üåç Flask API\n",
        "# -------------------------------\n",
        "app = Flask(__name__)\n",
        "CORS(app, resources={\n",
        "    r\"/*\": {\n",
        "        \"origins\": \"*\",\n",
        "        \"methods\": [\"GET\", \"POST\", \"OPTIONS\"],\n",
        "        \"allow_headers\": [\"Content-Type\"]\n",
        "    }\n",
        "})\n",
        "@app.route(\"/ping\", methods=[\"GET\"])\n",
        "def ping():\n",
        "    logger.info(\"üü¢ Ping\")\n",
        "    return jsonify({\n",
        "        \"status\": \"alive\",\n",
        "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        \"sessions\": len(STORE)\n",
        "    }), 200\n",
        "@app.route(\"/analyze\", methods=[\"POST\"])\n",
        "def analyze():\n",
        "    logger.info(\"=\" * 60)\n",
        "    logger.info(\"üÜï –ó–∞–ø—Ä–æ—Å /analyze\")\n",
        "\n",
        "    cleanup_old_sessions()\n",
        "    limit_sessions()\n",
        "\n",
        "    data = request.json or {}\n",
        "    site_url = data.get(\"site_url\")\n",
        "    existing_sid = data.get(\"session_id\")\n",
        "    if not site_url:\n",
        "        return jsonify({\"error\": \"–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å site_url\"}), 400\n",
        "    logger.info(f\"üåê URL: {site_url}\")\n",
        "\n",
        "    if existing_sid and existing_sid in STORE:\n",
        "        sid = existing_sid\n",
        "        logger.info(f\"‚ôªÔ∏è –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É—é session_id: {sid}\")\n",
        "        logger.info(f\"üóëÔ∏è –û—á–∏—â–∞—é —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏...\")\n",
        "    else:\n",
        "        sid = str(uuid.uuid4())\n",
        "        logger.info(f\"üÜï –°–æ–∑–¥–∞—é –Ω–æ–≤—ã–π session_id: {sid}\")\n",
        "    try:\n",
        "        main_prompt = fetch_gdoc_text(MAIN_PROMPT_URL)\n",
        "        site_data = crawl_site(site_url)\n",
        "        resp = call_main_model(OPENAI_CLIENT, main_prompt, site_data)\n",
        "        model_output = resp.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        logger.error(f\"‚ùå –û–®–ò–ë–ö–ê: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "    STORE[sid] = {\n",
        "        \"site\": site_data,\n",
        "        \"first_output\": model_output,\n",
        "        \"last_followup\": None,\n",
        "        \"history\": [],\n",
        "        \"created_at\": datetime.now()\n",
        "    }\n",
        "    logger.info(f\"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω\")\n",
        "    logger.info(f\"üìä –ê–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ—Å—Å–∏–π: {len(STORE)}\")\n",
        "    logger.info(\"=\" * 60)\n",
        "    return jsonify({\n",
        "        \"session_id\": sid,\n",
        "        \"result\": model_output,\n",
        "        \"pages\": site_data[\"count\"]\n",
        "    })\n",
        "@app.route(\"/followup\", methods=[\"POST\"])\n",
        "def followup():\n",
        "    logger.info(\"=\" * 60)\n",
        "    logger.info(\"üí¨ –ó–∞–ø—Ä–æ—Å /followup\")\n",
        "\n",
        "    data = request.json or {}\n",
        "    sid = data.get(\"session_id\")\n",
        "    user_instruction = data.get(\"followup_prompt\")\n",
        "    if not sid or sid not in STORE:\n",
        "        return jsonify({\"error\": \"session_id –Ω–µ –Ω–∞–π–¥–µ–Ω\"}), 404\n",
        "    logger.info(f\"üìù Session: {sid}\")\n",
        "    logger.info(f\"üí¨ –í–æ–ø—Ä–æ—Å: {user_instruction[:100]}...\")\n",
        "    sess = STORE[sid]\n",
        "    try:\n",
        "        followup_prompt_text = fetch_gdoc_text(FOLLOWUP_PROMPT_URL)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"‚ùå –û–®–ò–ë–ö–ê –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–º–ø—Ç–∞: {e}\")\n",
        "        return jsonify({\"error\": f\"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ follow-up –ø—Ä–æ–º–ø—Ç–∞: {e}\"}), 500\n",
        "    payload = {\n",
        "        \"first_output\": sess.get(\"first_output\"),\n",
        "        \"last_followup\": sess.get(\"last_followup\"),\n",
        "        \"conversation_history\": sess.get(\"history\", []),\n",
        "        \"user_instruction\": user_instruction\n",
        "    }\n",
        "    try:\n",
        "        resp = call_followup_model(OPENAI_CLIENT, followup_prompt_text, payload)\n",
        "        model_text = resp.choices[0].message.content\n",
        "        sess[\"last_followup\"] = model_text\n",
        "        sess[\"history\"].append({\"role\": \"user\", \"content\": user_instruction})\n",
        "        sess[\"history\"].append({\"role\": \"assistant\", \"content\": model_text})\n",
        "    except Exception as e:\n",
        "        logger.error(f\"‚ùå –û–®–ò–ë–ö–ê: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "    logger.info(f\"‚úÖ Follow-up –∑–∞–≤–µ—Ä—à—ë–Ω\")\n",
        "    logger.info(f\"üìä –°–æ–æ–±—â–µ–Ω–∏–π –≤ –∏—Å—Ç–æ—Ä–∏–∏: {len(sess['history'])}\")\n",
        "    logger.info(\"=\" * 60)\n",
        "    return jsonify({\n",
        "        \"result\": model_text\n",
        "    })\n",
        "@app.route(\"/clear-chat\", methods=[\"POST\"])\n",
        "def clear_chat():\n",
        "    logger.info(\"üßπ –ó–∞–ø—Ä–æ—Å /clear-chat\")\n",
        "\n",
        "    data = request.json or {}\n",
        "    sid = data.get(\"session_id\")\n",
        "    if not sid or sid not in STORE:\n",
        "        return jsonify({\"error\": \"session_id –Ω–µ –Ω–∞–π–¥–µ–Ω\"}), 404\n",
        "    sess = STORE[sid]\n",
        "    messages_count = len(sess.get(\"history\", []))\n",
        "\n",
        "    sess[\"history\"] = []\n",
        "    sess[\"last_followup\"] = None\n",
        "\n",
        "    logger.info(f\"‚úÖ –û—á–∏—â–µ–Ω–∞ –∏—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ –¥–ª—è {sid}\")\n",
        "    logger.info(f\"üìä –£–¥–∞–ª–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {messages_count}\")\n",
        "    logger.info(f\"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å–æ—Ö—Ä–∞–Ω—ë–Ω\")\n",
        "    return jsonify({\n",
        "        \"status\": \"success\",\n",
        "        \"message\": f\"–ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ –æ—á–∏—â–µ–Ω–∞ ({messages_count} —Å–æ–æ–±—â–µ–Ω–∏–π —É–¥–∞–ª–µ–Ω–æ)\",\n",
        "        \"session_id\": sid\n",
        "    }), 200\n",
        "def run_flask():\n",
        "    app.run(host=\"0.0.0.0\", port=PORT, use_reloader=False)\n",
        "# -------------------------------\n",
        "# üöÄ –ó–∞–ø—É—Å–∫\n",
        "# -------------------------------\n",
        "print(\"üîê –í–≤–µ–¥–∏—Ç–µ OpenAI API –∫–ª—é—á:\")\n",
        "OPENAI_API_KEY = getpass(\"API Key: \")\n",
        "OPENAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY)\n",
        "threading.Thread(target=run_flask, daemon=True).start()\n",
        "print(f\"‚öôÔ∏è Flask –Ω–∞ –ø–æ—Ä—Ç—É {PORT}\")\n",
        "print(\"üåê –ó–∞–ø—É—Å–∫ cloudflared...\")\n",
        "proc = subprocess.Popen(\n",
        "    [CLOUDFLARED_PATH, \"tunnel\", \"--url\", f\"http://localhost:{PORT}\", \"--no-autoupdate\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True\n",
        ")\n",
        "public_url = None\n",
        "for _ in range(60):\n",
        "    line = proc.stdout.readline()\n",
        "    if \"trycloudflare.com\" in line:\n",
        "        m = re.search(r\"(https://[^\\s]+trycloudflare\\.com)\", line)\n",
        "        if m:\n",
        "            public_url = m.group(1)\n",
        "            break\n",
        "if public_url:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"‚úÖ –°–ï–†–í–ï–† –ó–ê–ü–£–©–ï–ù!\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"üåê URL: {public_url}\")\n",
        "    print(f\"\\nüìå POST {public_url}/analyze\")\n",
        "    print(f\"üìå POST {public_url}/followup\")\n",
        "    print(f\"üìå POST {public_url}/clear-chat\")\n",
        "    print(f\"üü¢ GET {public_url}/ping\")\n",
        "    print(\"=\" * 60)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å URL.\")\n",
        "print(\"\\nüü¢ Colab –∞–∫—Ç–∏–≤–µ–Ω\")\n",
        "print(\"üí° –ù–∞—Å—Ç—Ä–æ–π –ø–∏–Ω–≥–∏ –∏–∑ WeWeb –Ω–∞ /ping –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç\")\n",
        "while True:\n",
        "    time.sleep(60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KfwoG-vbB17F",
        "outputId": "28147240-72df-4803-ce8f-120587357722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîΩ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é cloudflared...\n",
            "üîê –í–≤–µ–¥–∏—Ç–µ OpenAI API –∫–ª—é—á:\n",
            "API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚öôÔ∏è Flask –Ω–∞ –ø–æ—Ä—Ç—É 8000\n",
            "üåê –ó–∞–ø—É—Å–∫ cloudflared...\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:8000\n",
            " * Running on http://172.28.0.12:8000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "‚úÖ –°–ï–†–í–ï–† –ó–ê–ü–£–©–ï–ù!\n",
            "============================================================\n",
            "üåê URL: https://summit-configuration-tournament-avatar.trycloudflare.com\n",
            "\n",
            "üìå POST https://summit-configuration-tournament-avatar.trycloudflare.com/analyze\n",
            "üìå POST https://summit-configuration-tournament-avatar.trycloudflare.com/followup\n",
            "üìå POST https://summit-configuration-tournament-avatar.trycloudflare.com/clear-chat\n",
            "üü¢ GET https://summit-configuration-tournament-avatar.trycloudflare.com/ping\n",
            "============================================================\n",
            "\n",
            "üü¢ Colab –∞–∫—Ç–∏–≤–µ–Ω\n",
            "üí° –ù–∞—Å—Ç—Ä–æ–π –ø–∏–Ω–≥–∏ –∏–∑ WeWeb –Ω–∞ /ping –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:01:16] \"OPTIONS /analyze HTTP/1.1\" 200 -\n",
            "/tmp/ipython-input-1757423248.py:106: DeprecationWarning: The 'registered_domain' property is deprecated and will be removed in the next major version. Use 'top_domain_under_public_suffix' instead, which has the same behavior but a more accurate name.\n",
            "  return tldextract.extract(a).registered_domain == tldextract.extract(b).registered_domain\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:02:10] \"OPTIONS /ping HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:02:10] \"GET /ping HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:02:27] \"POST /analyze HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:06:11] \"OPTIONS /ping HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:06:11] \"GET /ping HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:10:12] \"OPTIONS /ping HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:10:12] \"GET /ping HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:14:13] \"OPTIONS /ping HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:14:14] \"GET /ping HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:18:15] \"OPTIONS /ping HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:18:15] \"GET /ping HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:22:17] \"OPTIONS /ping HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:22:18] \"GET /ping HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:26:20] \"OPTIONS /ping HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:26:20] \"GET /ping HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:30:22] \"OPTIONS /ping HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:30:23] \"GET /ping HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:34:25] \"OPTIONS /ping HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Nov/2025 17:34:26] \"GET /ping HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1757423248.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üí° –ù–∞—Å—Ç—Ä–æ–π –ø–∏–Ω–≥–∏ –∏–∑ WeWeb –Ω–∞ /ping –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}